# PRSNL Docker Configuration
# NOTE: We use local PostgreSQL for the main database
# This file is for Redis and other services only

services:
  # Database is now using local PostgreSQL (not Docker)
  # To use Docker database again, uncomment the db service below
  
  # db:
  #   image: pgvector/pgvector:pg16
  #   container_name: prsnl_db
  #   restart: unless-stopped
  #   environment:
  #     POSTGRES_DB: prsnl
  #     POSTGRES_USER: postgres
  #     POSTGRES_PASSWORD: postgres
  #   ports:
  #     - "${POSTGRES_PORT:-5432}:5432"
  #   volumes:
  #     - postgres_data:/var/lib/postgresql/data
  #     - ./backend/app/db/schema.sql:/docker-entrypoint-initdb.d/02-schema.sql
  #   healthcheck:
  #     test: ["CMD-SHELL", "pg_isready -U postgres -d prsnl"]
  #     interval: 10s
  #     timeout: 5s
  #     retries: 5

  # ===== NEO4J GRAPH DATABASE =====
  # Neo4j Community Edition for relationship analysis
  neo4j:
    image: neo4j:5.15-community
    container_name: prsnl_neo4j
    restart: unless-stopped
    ports:
      - "${NEO4J_HTTP_PORT:-7474}:7474"   # HTTP interface
      - "${NEO4J_BOLT_PORT:-7687}:7687"   # Bolt protocol
    environment:
      NEO4J_AUTH: ${NEO4J_USER:-neo4j}/${NEO4J_PASSWORD:-prsnl_graph_2024}
      NEO4J_PLUGINS: '["apoc", "graph-data-science"]'
      NEO4J_dbms_security_procedures_unrestricted: apoc.*,gds.*
      NEO4J_dbms_security_procedures_allowlist: apoc.*,gds.*
      NEO4J_dbms_memory_heap_initial__size: 512m
      NEO4J_dbms_memory_heap_max__size: 1G
      NEO4J_dbms_memory_pagecache_size: 256m
      NEO4J_dbms_logs_gc_enabled: false
      NEO4J_dbms_logs_gc_options: -XX:+UseG1GC
      NEO4J_dbms_logs_gc_rotation_keep__number: 5
      NEO4J_dbms_logs_gc_rotation_size: 20m
    volumes:
      - neo4j_data:/data
      - neo4j_logs:/logs
      - neo4j_import:/var/lib/neo4j/import
      - neo4j_plugins:/plugins
    healthcheck:
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:7474 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 40s

  # ===== LIBRECHAT SERVICES =====
  # LibreChat - Advanced Chat Interface
  librechat:
    image: ghcr.io/danny-avila/librechat-dev:latest
    container_name: prsnl_librechat
    restart: unless-stopped
    ports:
      - "${LIBRECHAT_PORT:-3080}:3080"
    depends_on:
      - librechat-mongo
      # - librechat-meilisearch  # Disabled - search functionality turned off
    env_file:
      - ./librechat.env
    environment:
      # Override with specific PRSNL settings
      AZURE_OPENAI_API_KEY: ${AZURE_OPENAI_API_KEY}
      RAG_PGVECTOR_CONNECTION_STRING: postgresql://pronav@host.docker.internal:5433/prsnl
    volumes:
      - ./librechat.yaml:/app/librechat.yaml
      - librechat_uploads:/app/uploads
      - librechat_logs:/app/logs
    extra_hosts:
      - "host.docker.internal:host-gateway"

  # MongoDB for LibreChat data storage
  librechat-mongo:
    image: mongo:6.0
    container_name: prsnl_librechat_mongo
    restart: unless-stopped
    environment:
      MONGO_INITDB_ROOT_USERNAME: admin
      MONGO_INITDB_ROOT_PASSWORD: ${LIBRECHAT_MONGO_PASSWORD:-secure_mongo_password}
    volumes:
      - librechat_mongo_data:/data/db

  # MeiliSearch for LibreChat search functionality
  # Uncomment this service and set SEARCH=true in librechat.env to enable chat search
  # librechat-meilisearch:
  #   image: getmeili/meilisearch:v1.5
  #   container_name: prsnl_librechat_meilisearch
  #   restart: unless-stopped
  #   environment:
  #     MEILI_MASTER_KEY: ${LIBRECHAT_MEILI_KEY:-secure_meili_key}
  #     MEILI_NO_ANALYTICS: true
  #     MEILI_ENV: production
  #   volumes:
  #     - librechat_meili_data:/meili_data

  # LibreChat RAG API - Disabled in favor of PRSNL's Haystack RAG
  # librechat-rag:
  #   image: ghcr.io/danny-avila/librechat-rag-api-dev:latest
  #   container_name: prsnl_librechat_rag
  #   restart: unless-stopped
  #   environment:
  #     RAG_PORT: 8000
  #     RAG_HOST: 0.0.0.0
  #     VECTOR_DB_TYPE: pgvector
  #     COLLECTION_NAME: prsnl_knowledge_base
  #     CHUNK_SIZE: 1500
  #     CHUNK_OVERLAP: 100
  #     RAG_PGVECTOR_CONNECTION_STRING: postgresql://pronav@host.docker.internal:5433/prsnl
  #     EMBEDDINGS_PROVIDER: azure
  #     EMBEDDINGS_MODEL: text-embedding-ada-002
  #     RAG_AZURE_OPENAI_ENDPOINT: https://airops.openai.azure.com
  #     RAG_AZURE_OPENAI_API_KEY: ${AZURE_OPENAI_API_KEY}
  #   volumes:
  #     - librechat_uploads:/app/uploads
  #   extra_hosts:
  #     - "host.docker.internal:host-gateway"

  redis:
    image: docker.dragonflydb.io/dragonflydb/dragonfly
    container_name: prsnl_redis
    restart: unless-stopped
    ports:
      - "${REDIS_PORT:-6379}:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Browserless - Browser automation for testing
  browserless:
    image: browserless/chrome:latest
    container_name: prsnl_browserless
    restart: unless-stopped
    ports:
      - "${BROWSERLESS_PORT:-3001}:3000"
    environment:
      CONCURRENT: 10
      TOKEN: ${BROWSERLESS_TOKEN:-}
      EXIT_ON_HEALTH_FAILURE: true
      PREBOOT_CHROME: true
      KEEP_ALIVE: true
      CHROME_REFRESH_TIME: 2000000
      DEFAULT_BLOCK_ADS: true
      DEFAULT_STEALTH: true
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/"]
      interval: 30s
      timeout: 10s
      retries: 3

  backend:
    build: ./backend
    container_name: prsnl_backend
    restart: unless-stopped
    ports:
      - "${BACKEND_PORT:-8000}:8000"
    volumes:
      - ./backend:/app
      - ./backend/media:/app/media
      - /Users/pronav/Library/Application Support/Arc:/chrome-profile:ro
    depends_on:
      # db:
      #   condition: service_healthy
      redis:
        condition: service_healthy
    environment:
      # Using local database instead of Docker
      DATABASE_URL: postgresql://pronav@host.docker.internal:5432/prsnl
      PG_CONN_STR: postgresql://postgres:postgres@db:5432/prsnl
      REDIS_URL: redis://redis:6379
      AZURE_OPENAI_API_KEY: ${AZURE_OPENAI_API_KEY}
      AZURE_OPENAI_ENDPOINT: https://airops.openai.azure.com
      AZURE_OPENAI_DEPLOYMENT: gpt-4.1
      AZURE_OPENAI_API_VERSION: 2025-01-01-preview
      AZURE_OPENAI_EMBEDDING_DEPLOYMENT: text-embedding-ada-002
      AZURE_OPENAI_WHISPER_DEPLOYMENT: whisper
      # Additional AI Services
      FIRECRAWL_API_KEY: ${FIRECRAWL_API_KEY}
      # Zero-cache code reloads
      PYTHONDONTWRITEBYTECODE: 1
      PYTHONUNBUFFERED: 1

  frontend:
    build: ./frontend
    container_name: prsnl_frontend
    restart: unless-stopped
    ports:
      - "${FRONTEND_PORT:-3003}:3003"
    environment:
      PUBLIC_API_URL: http://backend:8000
      NODE_ENV: development
      PORT: 3003
    depends_on:
      - backend

volumes:
  postgres_data:
  redis_data:
  # Neo4j volumes
  neo4j_data:
  neo4j_logs:
  neo4j_import:
  neo4j_plugins:
  # LibreChat volumes
  librechat_uploads:
  librechat_logs:
  librechat_mongo_data:
  librechat_meili_data: