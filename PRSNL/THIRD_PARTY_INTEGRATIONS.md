# üîó PRSNL Third-Party Integrations - Complete Guide

*Last Updated: 2025-07-13 - Phase 3 AI Second Brain Complete*

## Overview

PRSNL integrates with multiple third-party services to create a comprehensive AI-powered knowledge management system. This document provides complete implementation details, API references, and usage guidelines for all integrated services.

---

## ü§ñ AI & Machine Learning Services

### 1. Azure OpenAI (Primary AI Provider)

#### ‚úÖ Integration Status: **COMPLETE**
- **Purpose**: Primary AI processing with dual-model optimization
- **Models**: 
  - `prsnl-gpt-4`: Complex reasoning, AI workflows, function calling
  - `gpt-4.1-mini`: Fast chat responses, LibreChat integration
- **API Version**: `2023-12-01-preview` (function calling support)

#### Configuration
```python
# Environment Variables Required
AZURE_OPENAI_API_KEY=your-api-key
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_DEPLOYMENT=prsnl-gpt-4
AZURE_OPENAI_LIBRECHAT_DEPLOYMENT=gpt-4.1-mini
AZURE_OPENAI_API_VERSION=2023-12-01-preview
```

#### API Endpoints
- **LibreChat Bridge**: `/api/ai/*` - OpenAI-compatible chat completions
- **AI Integration**: `/api/ai/*` - AI-powered workflows
- **Function Calling**: Full tools API support with parallel execution

#### Usage Example
```bash
# Chat completion with knowledge base context
curl -X POST http://localhost:8000/api/ai/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "prsnl-gpt-4",
    "messages": [{"role": "user", "content": "How does PRSNL work?"}],
    "temperature": 0.7
  }'

# AI-powered insights
curl -X POST http://localhost:8000/api/ai-suggest \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "Create a learning path for FastAPI",
    "context": {"current_knowledge": ["Python basics"]}
  }'
```

---

### 2. OpenCLIP Vision Service

#### ‚úÖ Integration Status: **COMPLETE** (NEW API Endpoints Added)
- **Purpose**: Advanced image understanding and visual-semantic search
- **Model**: Configurable via `OPENCLIP_MODEL` and `OPENCLIP_PRETRAINED`
- **Capabilities**: Image encoding, text encoding, similarity computation, image description

#### Configuration
```python
# Environment Variables
OPENCLIP_MODEL=ViT-B-32
OPENCLIP_PRETRAINED=openai
```

#### API Endpoints (NEW)
All endpoints available at `/api/openclip/*`:

```bash
# Model information
GET /api/openclip/health
GET /api/openclip/model-info

# Encoding services
POST /api/openclip/encode/text
POST /api/openclip/encode/image
POST /api/openclip/encode/image-base64

# Similarity computation
POST /api/openclip/similarity
POST /api/openclip/similarity-base64

# Image description generation
POST /api/openclip/describe-image
POST /api/openclip/describe-image-base64

# Text matching
POST /api/openclip/find-best-match
POST /api/openclip/find-best-match-base64

# Batch processing
POST /api/openclip/batch/encode-text

# Utility endpoints
GET /api/openclip/supported-formats
GET /api/openclip/examples
```

#### Usage Examples
```bash
# Encode text to feature vector
curl -X POST http://localhost:8000/api/openclip/encode/text \
  -H "Content-Type: application/json" \
  -d '{"text": "a photo of a cat"}'

# Upload and describe image
curl -X POST http://localhost:8000/api/openclip/describe-image \
  -F "file=@image.jpg"

# Compute image-text similarity
curl -X POST http://localhost:8000/api/openclip/similarity \
  -F "text=a beautiful landscape" \
  -F "file=@landscape.jpg"

# Batch encode multiple texts
curl -X POST http://localhost:8000/api/openclip/batch/encode-text \
  -H "Content-Type: application/json" \
  -d '{
    "texts": [
      "a photo of a cat",
      "a picture of a dog", 
      "an image of a bird"
    ]
  }'
```

#### Rate Limits
- **30 requests per minute** for all OpenCLIP endpoints
- Automatic throttling for resource-intensive operations

---

## üï∑Ô∏è Web Scraping & Content Extraction

### 3. Firecrawl

#### ‚úÖ Integration Status: **COMPLETE**
- **Purpose**: Advanced web scraping with JavaScript rendering
- **Capabilities**: URL crawling, content extraction, PDF handling, JavaScript execution
- **Service**: `FirecrawlService` with comprehensive error handling

#### Configuration
```python
# Environment Variables
FIRECRAWL_API_KEY=your-firecrawl-api-key
FIRECRAWL_BASE_URL=https://api.firecrawl.dev
```

#### API Endpoints
```bash
# Single URL scraping
POST /api/firecrawl/scrape

# Batch URL crawling
POST /api/firecrawl/crawl

# Job status checking
GET /api/firecrawl/job/{job_id}

# Service health check
GET /api/firecrawl/health
```

#### Usage Examples
```bash
# Scrape a single URL
curl -X POST http://localhost:8000/api/firecrawl/scrape \
  -H "Content-Type: application/json" \
  -d '{
    "url": "https://example.com",
    "formats": ["markdown", "html"],
    "includeTags": ["h1", "h2", "p"],
    "onlyMainContent": true
  }'

# Crawl multiple pages
curl -X POST http://localhost:8000/api/firecrawl/crawl \
  -H "Content-Type: application/json" \
  -d '{
    "url": "https://docs.example.com",
    "crawlerOptions": {
      "includes": ["docs/**"],
      "excludes": ["docs/private/**"],
      "maxDepth": 3,
      "limit": 100
    },
    "pageOptions": {
      "onlyMainContent": true,
      "formats": ["markdown"]
    }
  }'
```

#### Error Handling
- Automatic retries with exponential backoff
- Graceful fallback to basic scraping
- Comprehensive logging and monitoring

---

## üóÑÔ∏è Database & Storage Systems

### 4. DragonflyDB (Cache Layer)

#### ‚úÖ Integration Status: **COMPLETE** (25x Performance Improvement)
- **Purpose**: Ultra-fast caching replacing Redis
- **Performance**: 25x faster than Redis with superior memory efficiency
- **Port**: 6379 (Redis-compatible protocol)

#### Configuration
```yaml
# docker-compose.yml
services:
  redis:  # Named 'redis' for compatibility
    image: docker.dragonflydb.io/dragonflydb/dragonfly:latest
    ports:
      - "6379:6379"
    command: ["--alsologtostderr"]
```

#### Usage
```python
# Automatic usage through existing Redis clients
from app.services.cache import cache_service

# All existing Redis operations work seamlessly
await cache_service.set("key", "value", ttl=3600)
result = await cache_service.get("key")
```

### 5. ARM64 PostgreSQL 16

#### ‚úÖ Integration Status: **COMPLETE** (Apple Silicon Optimized)
- **Purpose**: Primary database with vector search capabilities
- **Port**: 5433 (ARM64 optimized, not 5432!)
- **Extensions**: pgvector for AI embeddings

#### Configuration
```python
# Database connection
DATABASE_URL=postgresql://pronav@localhost:5433/prsnl
```

#### Key Features
- ARM64 architecture optimization for Apple Silicon
- pgvector extension for semantic search
- Optimized for high-performance AI workloads

---

## ‚ö° Performance & Infrastructure

### 6. uvloop (Async Performance)

#### ‚úÖ Integration Status: **COMPLETE** (2-4x Performance Boost)
- **Purpose**: Ultra-fast asyncio event loop
- **Performance**: 2-4x faster than standard Python asyncio
- **Platform**: Non-Windows platforms only

```python
# Automatic installation in main.py
import uvloop
if sys.platform != 'win32':
    uvloop.install()
    logging.info("üöÄ uvloop installed - async performance optimized")
```

### 7. slowapi (Rate Limiting)

#### ‚úÖ Integration Status: **COMPLETE**
- **Purpose**: Native Starlette-based rate limiting
- **Consolidation**: Replaced multiple rate limiting libraries
- **Endpoints**: Custom limits per service type

#### Rate Limiting Configuration
```python
# Service-specific rate limits
capture_limiter = "10 per minute"      # Content capture
search_limiter = "30 per minute"       # Search operations
openclip_limiter = "30 per minute"     # Vision processing
embedding_limiter = "5 per 5 minutes"  # Embedding generation
file_upload_limiter = "15 per 5 minutes"  # File uploads
```

### 8. httpx (HTTP Client)

#### ‚úÖ Integration Status: **COMPLETE** (Standardized)
- **Purpose**: Modern async HTTP client
- **Standardization**: Replaced multiple HTTP clients (aiohttp, requests)
- **Usage**: All external API communications

---

## üîÑ API & Communication

### 9. LibreChat Integration Bridge

#### ‚úÖ Integration Status: **COMPLETE** (OpenAI Compatible)
- **Purpose**: OpenAI-compatible chat interface
- **Knowledge Base**: Automatic PRSNL context integration
- **Streaming**: Real-time response delivery
- **Model**: Optimized with gpt-4.1-mini for fast responses

#### API Endpoints
```bash
# OpenAI-compatible chat completions
POST /api/ai/chat/completions

# Available models
GET /api/ai/models

# Health check
GET /api/ai/health
```

### 10. AI Services Integration

#### ‚úÖ Integration Status: **COMPLETE**
- **Purpose**: Autonomous AI knowledge curation and analysis
- **Capabilities**: 
  - Content analysis and categorization
  - Multi-source synthesis and insights
  - Relationship discovery and exploration
  - Personalized recommendations

#### API Endpoints
```bash
# AI service health
GET /api/ai/health

# AI-powered suggestions
POST /api/ai-suggest

# Content summarization
POST /api/summarization/summarize/batch

# AI chat completions
POST /api/ai/chat/completions

# Model information
GET /api/ai/models
```

---

## üì± Browser & Mobile Extensions

### 11. Chrome Extension

#### ‚úÖ Integration Status: **COMPLETE** (Fixed & Enhanced)
- **Purpose**: Browser-based content capture
- **Features**: GitHub auto-detection, CSP compliance, modern styling
- **Styling**: 259+ lines of comprehensive form CSS

#### Key Features
- Automatic GitHub URL detection as 'development' content
- WebSocket-free architecture for security compliance
- Professional styling with neural theme integration
- Cross-platform integration with frontend and backend

---

## üîß Configuration & Environment

### Required Environment Variables

#### Core Configuration
```bash
# Database (ARM64 PostgreSQL 16)
DATABASE_URL=postgresql://pronav@localhost:5433/prsnl

# Azure OpenAI (Dual-Model Strategy)
AZURE_OPENAI_API_KEY=your-key
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_DEPLOYMENT=prsnl-gpt-4
AZURE_OPENAI_LIBRECHAT_DEPLOYMENT=gpt-4.1-mini
AZURE_OPENAI_API_VERSION=2023-12-01-preview

# OpenCLIP Vision
OPENCLIP_MODEL=ViT-B-32
OPENCLIP_PRETRAINED=openai

# Firecrawl Web Scraping
FIRECRAWL_API_KEY=your-firecrawl-key
FIRECRAWL_BASE_URL=https://api.firecrawl.dev

# Performance & Caching
CACHE_ENABLED=true
RATE_LIMITING_ENABLED=true

# Development
DEBUG_ROUTES=false
ENVIRONMENT=development
BACKEND_PORT=8000
```

#### AI Configuration
```bash
# Azure OpenAI settings
AZURE_OPENAI_API_VERSION=2023-12-01-preview
AZURE_OPENAI_DEPLOYMENT=prsnl-gpt-4
```

---

## üß™ Testing & Verification

### Health Check Commands
```bash
# Check all service status
curl http://localhost:8000/health

# Azure OpenAI models
curl http://localhost:8000/api/ai/models

# AI service status
curl http://localhost:8000/api/ai/health

# OpenCLIP service
curl http://localhost:8000/api/openclip/health

# Firecrawl service
curl http://localhost:8000/api/firecrawl/health
```

### Integration Testing
```bash
# Test LibreChat integration
curl -X POST http://localhost:8000/api/ai/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "prsnl-gpt-4",
    "messages": [{"role": "user", "content": "Test response"}]
  }'

# Test AI workflow
curl -X POST http://localhost:8000/api/ai-suggest \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "Analyze this content",
    "context": {"title": "Test Article"}
  }'

# Test OpenCLIP vision
curl -X POST http://localhost:8000/api/openclip/encode/text \
  -H "Content-Type: application/json" \
  -d '{"text": "test encoding"}'

# Test Firecrawl scraping
curl -X POST http://localhost:8000/api/firecrawl/scrape \
  -H "Content-Type: application/json" \
  -d '{
    "url": "https://httpbin.org/html",
    "formats": ["markdown"]
  }'
```

---

## üöÄ Performance Metrics

### Response Times (Phase 3 Verified)
- **LibreChat**: 4.0s (streaming), 5.5s (regular completion)
- **AI Processing**: 2-5s (context-aware responses)
- **OpenCLIP**: Sub-second for most operations
- **Firecrawl**: 2-15s depending on page complexity

### Throughput Improvements
- **uvloop**: 2-4x async performance boost
- **DragonflyDB**: 25x faster than Redis
- **ARM64 PostgreSQL**: Optimized for Apple Silicon
- **httpx**: Consistent HTTP performance

---

## üîç OpenAI Operator vs OpenCLIP Comparison

### OpenAI's New Operator (Hypothetical)
**Advantages:**
- Latest OpenAI technology
- Likely better performance for text-based operations
- Integrated with GPT models
- Strong function calling capabilities

**Use Cases:**
- Complex multi-step workflows
- Advanced reasoning tasks
- Text-based AI operations

### OpenCLIP (Currently Integrated)
**Advantages:**
- ‚úÖ **Already Integrated & Working**
- Specialized for vision tasks
- Open-source and customizable
- Excellent for image-text matching
- No additional API costs

**Use Cases:**
- Image understanding and description
- Visual search and similarity
- Content classification by visual features
- Multi-modal search experiences

### **Recommendation**: 
**Keep OpenCLIP** for vision tasks and **consider OpenAI Operator** for enhanced text workflows when it becomes available. They serve complementary purposes in the AI stack.

---

## üìã Integration Roadmap

### ‚úÖ Phase 3 Complete (Current)
- Azure OpenAI dual-model optimization
- AI-powered content analysis
- LibreChat integration bridge
- OpenCLIP REST API endpoints
- DragonflyDB performance upgrade
- ARM64 PostgreSQL optimization

### üîÑ Future Enhancements
- OpenAI Operator integration (when available)
- Enhanced monitoring and observability
- Advanced caching strategies
- Multi-model AI routing
- Extended rate limiting features

---

## üÜò Troubleshooting

### Common Issues

#### OpenCLIP Not Available
```bash
# Install OpenCLIP dependencies
pip install open-clip-torch
```

#### Firecrawl API Errors
```bash
# Check API key configuration
echo $FIRECRAWL_API_KEY
curl -H "Authorization: Bearer $FIRECRAWL_API_KEY" https://api.firecrawl.dev/health
```

#### Azure OpenAI Function Calling Issues
```bash
# Verify API version supports function calling
# Must be 2023-07-01-preview or later
echo $AZURE_OPENAI_API_VERSION
```

#### DragonflyDB Connection Issues
```bash
# Check DragonflyDB status
docker ps | grep dragonfly
docker logs prsnl_redis
```

### Performance Issues
1. **High Response Times**: Check rate limiting, increase cache TTL
2. **Memory Usage**: Monitor DragonflyDB and OpenCLIP model loading
3. **Database Slowness**: Verify ARM64 PostgreSQL on port 5433
4. **API Timeouts**: Adjust timeout settings for external services

---

## üìö Additional Resources

- **API Documentation**: http://localhost:8000/docs
- **AI Integration Guide**: `/docs/AI_INTEGRATION_GUIDE.md`
- **LibreChat Setup**: `/docs/LIBRECHAT_INTEGRATION.md`
- **Performance Tuning**: `/docs/PERFORMANCE_OPTIMIZATION.md`
- **Architecture Overview**: `/docs/ARCHITECTURE.md`

---

*This document reflects the complete integration status as of Phase 3 completion. All services are operational and tested with real AI responses and workflows.*